# -*- coding: utf-8 -*-
"""
AIç®€å†åˆç­›åç«¯æœåŠ¡
FastAPI åç«¯æœåŠ¡ - å¤„ç†ç®€å†åˆç­›è¯·æ±‚
åŠŸèƒ½ï¼š
1. æ¥æ”¶ä¸Šä¼ çš„ä¸¤ä¸ª Excel æ–‡ä»¶
2. è°ƒç”¨è§£æè„šæœ¬è½¬æ¢ä¸º JSON
3. ç›´æ¥è°ƒç”¨ LLM ç­›é€‰æ¨¡å—è¿›è¡Œç­›é€‰
"""
import os
import json
import shutil
import tempfile
import asyncio
import time
from typing import List
from datetime import datetime
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn

# å¯¼å…¥ç°æœ‰çš„è§£æè„šæœ¬
import sys
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)  # å›åˆ°æ¡ä»¶è¾ƒä¸ºç®€å•+å•è¡Œè¡¨ç›®å½•
sys.path.insert(0, parent_dir)

# å¯¼å…¥è§£æå‡½æ•°ï¼ˆä» parsers ç›®å½•ï¼‰
from parsers.detect_merged_cells_with_accuracy_dan import parse_excel_to_single_row_json
from parsers.detect_merged_cells_with_accuracy_position_adjust import parse_excel_to_position_json

# å¯¼å…¥ LLM ç­›é€‰æ¨¡å—
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))
llm_filter_path = os.path.join(project_root, "7.LLM_resume_filter")
sys.path.insert(0, llm_filter_path)

from core.screener import ResumeScreener
from managers.llm_manager import get_model_manager
from utils.logger_config import setup_logger

# åˆå§‹åŒ–æ—¥å¿—
logger = setup_logger("backend_service")

app = FastAPI(title="AIç®€å†åˆç­›ç³»ç»Ÿ", version="2.0.0")

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”è¯¥è®¾ç½®å…·ä½“çš„åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡ï¼šæ¨¡å‹ç®¡ç†å™¨å’Œç­›é€‰å™¨
model_manager = None
screener = None


@app.on_event("startup")
async def startup_event():
    """æœåŠ¡å¯åŠ¨æ—¶åˆå§‹åŒ–"""
    global model_manager, screener
    
    logger.info("ğŸš€ æ­£åœ¨åˆå§‹åŒ– AI ç®€å†åˆç­›æœåŠ¡...")
    
    # è·å–LLM Studioæ¨¡å‹ç®¡ç†å™¨
    model_manager = get_model_manager()
    
    if model_manager:
        logger.info("âœ… å·²åŠ è½½æ¨¡å‹ç®¡ç†å™¨ï¼Œå¯ä»¥ä½¿ç”¨LLMè¿›è¡Œç­›é€‰")
    else:
        logger.warning("âš ï¸  æ¨¡å‹ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼ŒLLMç­›é€‰åŠŸèƒ½ä¸å¯ç”¨")
    
    # ä¸“ä¸šåº“è·¯å¾„
    major_library_path = os.path.join(llm_filter_path, "data/ä¸“ä¸šåº“.json")
    
    # é™¢æ ¡åº“è·¯å¾„
    school_library_path = os.path.join(llm_filter_path, "data/é™¢æ ¡åº“.json")
    
    # åˆå§‹åŒ–ç­›é€‰å™¨
    screener = ResumeScreener(model_manager=model_manager, major_library_path=major_library_path, school_library_path=school_library_path)
    
    logger.info("âœ… AI ç®€å†åˆç­›æœåŠ¡åˆå§‹åŒ–å®Œæˆ")


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "AIç®€å†åˆç­›ç³»ç»Ÿ",
        "version": "2.0.0",
        "llm_available": model_manager is not None,
        "endpoints": {
            "/": "ç³»ç»Ÿä¿¡æ¯",
            "/health": "å¥åº·æ£€æŸ¥",
            "/api/screen": "ç®€å†åˆç­›æ¥å£ (POST)"
        }
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "ok",
        "message": "æœåŠ¡è¿è¡Œæ­£å¸¸",
        "llm_available": model_manager is not None
    }


@app.post("/api/screen")
async def screen_resumes(
    resume_file: UploadFile = File(..., description="ç®€å†å¯¼å…¥å¤šè¡Œè¡¨Excelæ–‡ä»¶"),
    position_file: UploadFile = File(..., description="å²—ä½éœ€æ±‚æ˜ç»†è¡¨Excelæ–‡ä»¶")
):
    """
    ç®€å†åˆç­›æ¥å£
    æ¥æ”¶ä¸¤ä¸ª Excel æ–‡ä»¶,è¿”å›ç­›é€‰ç»“æœ
    
    æ³¨æ„ï¼šä¸ºç¡®ä¿ç»“æœä¸€è‡´æ€§ï¼Œå²—ä½æ•°æ®ç›´æ¥ä½¿ç”¨ 7.LLM_resume_filter ä¸­çš„JSONæ–‡ä»¶
    """
    temp_dir = None
    try:
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = tempfile.mkdtemp()
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        resume_path = os.path.join(temp_dir, resume_file.filename)
        position_path = os.path.join(temp_dir, position_file.filename)
        
        with open(resume_path, "wb") as f:
            shutil.copyfileobj(resume_file.file, f)
        
        with open(position_path, "wb") as f:
            shutil.copyfileobj(position_file.file, f)
        
        # è§£æç®€å†æ–‡ä»¶
        print(f"â³ æ­£åœ¨è§£æç®€å†æ–‡ä»¶: {resume_file.filename}")
        resumes_data = parse_excel_to_single_row_json(resume_path)
        
        if not resumes_data:
            raise HTTPException(status_code=400, detail="ç®€å†æ–‡ä»¶è§£æå¤±è´¥")
        
        print(f"âœ… ç®€å†è§£æå®Œæˆï¼Œå…± {len(resumes_data)} æ¡è®°å½•")
        
        # ä¿å­˜è§£æåçš„JSONåˆ°dataæ–‡ä»¶å¤¹
        data_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data")
        os.makedirs(data_dir, exist_ok=True)
        
        # ç”Ÿæˆç®€å†JSONæ–‡ä»¶åï¼ˆåŸºäºä¸Šä¼ çš„æ–‡ä»¶åï¼‰
        resume_json_filename = os.path.splitext(resume_file.filename)[0] + ".json"
        resume_json_path = os.path.join(data_dir, resume_json_filename)
        
        with open(resume_json_path, 'w', encoding='utf-8') as f:
            json.dump(resumes_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ç®€å†JSONå·²ä¿å­˜åˆ°: {resume_json_path}")
        
        # è§£æå²—ä½æ–‡ä»¶
        print(f"â³ æ­£åœ¨è§£æå²—ä½æ–‡ä»¶: {position_file.filename}")
        positions_data = parse_excel_to_position_json(position_path)
        
        if not positions_data:
            raise HTTPException(status_code=400, detail="å²—ä½æ–‡ä»¶è§£æå¤±è´¥")
        
        print(f"âœ… å²—ä½è§£æå®Œæˆï¼Œå…± {len(positions_data)} ä¸ªå²—ä½")
        
        # ç”Ÿæˆå²—ä½JSONæ–‡ä»¶åï¼ˆåŸºäºä¸Šä¼ çš„æ–‡ä»¶åï¼‰
        position_base_name = os.path.splitext(position_file.filename)[0]
        
        # 1. ä¿å­˜åŸå§‹æ–‡ä»¶åï¼ˆåŒ…å«åŸæ–‡å’Œè§„æ•´åï¼‰
        position_json_filename = position_base_name + ".json"
        position_json_path = os.path.join(data_dir, position_json_filename)
        
        with open(position_json_path, 'w', encoding='utf-8') as f:
            json.dump(positions_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ å²—ä½JSONå·²ä¿å­˜åˆ°: {position_json_path}")
        
        # 2. ä¿å­˜å¸¦"_è§„æ•´å"åç¼€çš„æ–‡ä»¶åï¼ˆåŒæ ·åŒ…å«åŸæ–‡å’Œè§„æ•´åï¼‰
        position_normalized_filename = position_base_name + "_è§„æ•´å.json"
        position_normalized_path = os.path.join(data_dir, position_normalized_filename)
        
        with open(position_normalized_path, 'w', encoding='utf-8') as f:
            json.dump(positions_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ å²—ä½JSONï¼ˆè§„æ•´åï¼‰å·²ä¿å­˜åˆ°: {position_normalized_path}")
        
        # ç›´æ¥è°ƒç”¨ LLM ç­›é€‰æ¨¡å—
        print("â³ æ­£åœ¨æ‰§è¡Œ AI ç­›é€‰...")
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # å¹¶å‘ç­›é€‰æ‰€æœ‰å²—ä½
        async def screen_job_with_info(job):
            """ç­›é€‰å•ä¸ªå²—ä½å¹¶è¿”å›ç»“æœ"""
            job_name = job.get('å²—ä½', f"å²—ä½{job.get('åºå·', 'æœªçŸ¥')}")
            job_id = job.get('åºå·', 0)
            logger.info(f"[å¹¶å‘] ğŸ“Œ å¼€å§‹ç­›é€‰å²—ä½ {job_id}: {job_name}")
            
            results = await screener.screen_batch(job, resumes_data, resume_file="ä¸Šä¼ æ–‡ä»¶")
            
            logger.info(f"[å¹¶å‘] âœ… å²—ä½ {job_name} ç­›é€‰å®Œæˆï¼Œå…± {len(results)} ä»½ç®€å†")
            return job, results
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰å²—ä½çš„ç­›é€‰
        job_results_list = await asyncio.gather(*[screen_job_with_info(job) for job in positions_data])
        
        # æ•´ç†ç»“æœ
        all_results = []
        for job, results in job_results_list:
            all_results.extend(results)
        
        # è°ƒè¯•ä¿¡æ¯
        logger.info(f"ğŸ“Š æ€»ç­›é€‰ç»“æœæ•°: {len(all_results)}")
        
        # è®¡ç®—è€—æ—¶
        elapsed_time = time.time() - start_time
        
        # æ„å»ºè¾“å‡ºç»“æœ
        screening_results = []
        
        # åˆ›å»ºä¸€ä¸ªå·²å¤„ç†çš„ç®€å†é›†åˆï¼ˆä½¿ç”¨åºå·+å§“åé¿å…é‡å¤ï¼‰
        processed_resumes = set()
        
        for result in all_results:
            resume_id = result.resume_id
            job_name_from_result = result.job_name
            
            logger.info(f"ğŸ” å¤„ç†ç­›é€‰ç»“æœ: resume_id={resume_id}, job_name={job_name_from_result}")
            
            # ä» filter_details ä¸­æå–å§“åï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            name_from_result = None
            if result.filter_details and len(result.filter_details) > 0:
                resume_info = result.filter_details[0].get('resume_info', '')
                # resume_info æ ¼å¼: "åºå·=2 | å§“å=å¼ ä¸‰ | å­¦å†=åšå£«ç ”ç©¶ç”Ÿ | å­¦æ ¡=æ¸…åå¤§å­¦"
                if 'å§“å=' in resume_info:
                    parts = resume_info.split('|')
                    for part in parts:
                        if 'å§“å=' in part:
                            name_from_result = part.split('å§“å=')[1].strip()
                            break
            
            logger.info(f"   ä»ç»“æœä¸­æå–çš„å§“å: {name_from_result}")
            
            # ä»resumesåˆ—è¡¨ä¸­æŸ¥æ‰¾ç®€å†æ•°æ®
            matching_resumes = [resume for resume in resumes_data if str(resume.get('åºå·', '')) == resume_id]
            
            logger.info(f"   æ‰¾åˆ° {len(matching_resumes)} ä¸ªåŒ¹é…çš„ç®€å†è®°å½•")
            
            if not matching_resumes:
                logger.warning(f"âš ï¸  æœªæ‰¾åˆ°ç®€å†æ•°æ®ï¼šresume_id={resume_id}")
                continue
            
            # æ‰¾åˆ°æ­£ç¡®çš„ç®€å†
            resume_data = None
            if len(matching_resumes) == 1:
                resume_data = matching_resumes[0]
                logger.info(f"   å”¯ä¸€åŒ¹é…ï¼Œç›´æ¥ä½¿ç”¨")
            else:
                # æœ‰å¤šä¸ªç›¸åŒåºå·çš„ç®€å†ï¼Œé€šè¿‡å§“ååŒ¹é…
                logger.info(f"   å¤šä¸ªåŒ¹é…ï¼Œé€šè¿‡å§“ååŒ¹é…: {name_from_result}")
                if name_from_result:
                    for resume in matching_resumes:
                        name = resume.get('åŸºæœ¬ä¿¡æ¯', {}).get('å§“å', '')
                        if name == name_from_result:
                            resume_data = resume
                            logger.info(f"     âœ… æ‰¾åˆ°åŒ¹é…çš„ç®€å†: {name}")
                            break
                
                # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæœªå¤„ç†çš„
                if not resume_data:
                    logger.warning(f"   âš ï¸  æ— æ³•é€šè¿‡å§“ååŒ¹é…ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæœªå¤„ç†çš„ç®€å†")
                    for resume in matching_resumes:
                        name = resume.get('åŸºæœ¬ä¿¡æ¯', {}).get('å§“å', '')
                        unique_key = f"{resume_id}_{name}"
                        if unique_key not in processed_resumes:
                            resume_data = resume
                            logger.info(f"     âœ… ä½¿ç”¨æœªå¤„ç†çš„ç®€å†: {name}")
                            break
                
                # å¦‚æœæ‰€æœ‰éƒ½å¤„ç†è¿‡äº†ï¼Œè·³è¿‡
                if not resume_data:
                    logger.warning(f"   âš ï¸  æ‰€æœ‰åŒ¹é…çš„ç®€å†éƒ½å·²å¤„ç†è¿‡ï¼Œè·³è¿‡")
                    continue
            
            # æ ‡è®°ä¸ºå·²å¤„ç†
            name = resume_data.get('åŸºæœ¬ä¿¡æ¯', {}).get('å§“å', '')
            unique_key = f"{resume_id}_{name}"
            processed_resumes.add(unique_key)
            
            # è·å–åŸºæœ¬ä¿¡æ¯
            basic_info = resume_data.get('åŸºæœ¬ä¿¡æ¯', {})
            name = basic_info.get('å§“å', '')
            resume_number = resume_data.get('åºå·', '')
            
            # è·å–å²—ä½ä¿¡æ¯
            job_info = resume_data.get('å²—ä½ä¿¡æ¯', {})
            applied_position = job_info.get('åº”è˜å²—ä½', '')
            
            # è·å–å­¦ä¹ ç»å†ç»Ÿè®¡ä¿¡æ¯
            education_info = resume_data.get('å­¦ä¹ ç»å†ç»Ÿè®¡ä¿¡æ¯', {})
            highest_education = education_info.get('æœ€é«˜å­¦å†', '')
            highest_school = education_info.get('æœ€é«˜å­¦å†æ¯•ä¸šé™¢æ ¡', '')
            highest_school_type = education_info.get('æœ€é«˜å­¦å†æ¯•ä¸šé™¢æ ¡ç±»å‹', '')
            
            # è®¡ç®—å¹´é¾„
            birth_date = basic_info.get('å‡ºç”Ÿæ—¥æœŸ', '')
            age = ''
            if birth_date:
                try:
                    date_part = birth_date.split()[0] if ' ' in birth_date else birth_date
                    parts = date_part.split('-')
                    if len(parts) >= 1:
                        year = int(parts[0])
                        month = int(parts[1]) if len(parts) > 1 else 1
                        day = int(parts[2]) if len(parts) > 2 else 1
                        current_date = datetime.now()
                        age_calc = current_date.year - year
                        if (current_date.month, current_date.day) < (month, day):
                            age_calc -= 1
                        age = str(age_calc)
                except:
                    pass
            
            # æ„å»ºå…³é”®ç”»åƒ
            key_profile_parts = []
            if highest_education:
                key_profile_parts.append(highest_education)
            if highest_school:
                key_profile_parts.append(highest_school)
            if highest_school_type:
                key_profile_parts.append(highest_school_type)
            if age:
                key_profile_parts.append(f"{age}å²")
            
            key_profile = ' | '.join(key_profile_parts) if key_profile_parts else ''
            
            # è·å–ç°èŒåŠ¡æˆ–å²—ä½
            current_position = basic_info.get('ç°èŒåŠ¡æˆ–å²—ä½', '')
            if current_position:
                key_profile += f"\nç°ä»»ï¼š{current_position}"
            
            # æ„å»ºAIåˆç­›ç»“æœ
            ai_result = "æ‹Ÿé€šè¿‡" if result.passed else "æ‹Ÿæ·˜æ±°"
            
            # æ„å»ºæ·˜æ±°åŸå› 
            failed_filters = [detail.get('filter_name') for detail in result.filter_details if not detail.get('passed')]
            elimination_reason = '/'.join(failed_filters) if failed_filters else ''
            
            # æ„å»ºç­›é€‰æ¡ä»¶è¯¦æƒ…
            filter_details = []
            for detail in result.filter_details:
                filter_name = detail.get('filter_name', '')
                passed = detail.get('passed', False)
                method = detail.get('method', detail.get('source', 'æœªçŸ¥'))
                reason = detail.get('reason', '')
                
                # è·å–ç­›é€‰è¯¦æƒ…
                detail_info = detail.get('details', {})
                detail_text = ''
                if isinstance(detail_info, dict):
                    detail_text = detail_info.get('detail', '')
                
                # æ ¼å¼åŒ–åŸå› è¯´æ˜ï¼šå»æ‰"åŸæ–‡"å­—æ®µ
                import re
                # å¦‚æœreasonä¸­åŒ…å«requirementå­—å…¸ï¼Œå»æ‰"åŸæ–‡"å­—æ®µ
                if "'åŸæ–‡'" in reason or '"åŸæ–‡"' in reason:
                    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å»æ‰"åŸæ–‡"å­—æ®µåŠå…¶å€¼ï¼Œå¹¶å¤„ç†å¤šä½™çš„é€—å·
                    reason = re.sub(r"['\"]åŸæ–‡['\"]\s*:\s*[^,}]+,\s*", "", reason)  # å…ˆå¤„ç†åé¢æœ‰é€—å·çš„æƒ…å†µ
                    reason = re.sub(r",?\s*['\"]åŸæ–‡['\"]\s*:\s*[^,}]+", "", reason)  # å†å¤„ç†å…¶ä»–æƒ…å†µ
                    # æ¸…ç†å¯èƒ½ç•™ä¸‹çš„å¤šä½™é€—å·å’Œç©ºæ ¼
                    reason = re.sub(r",\s*,", ",", reason)  # å»æ‰è¿ç»­é€—å·
                    reason = re.sub(r"{\s*,", "{", reason)  # å»æ‰{åçš„é€—å·
                
                # åœ¨ç­›é€‰è¯¦æƒ…æœ«å°¾æ·»åŠ é€—å·ï¼ˆå¦‚æœdetail_textä¸ä¸ºç©ºï¼‰
                if detail_text:
                    detail_text = detail_text.rstrip() + ','
                
                # è½¬æ¢åˆ¤æ–­æ–¹æ³•
                if method == 'rule' or 'è§„åˆ™' in str(method):
                    method_display = 'è§„åˆ™'
                elif method == 'llm' or 'LLM' in str(method):
                    method_display = 'LLM'
                else:
                    method_display = str(method)
                
                filter_detail = {
                    "ç­›é€‰æ¡ä»¶": filter_name,
                    "æ˜¯å¦é€šè¿‡": "é€šè¿‡" if passed else "ä¸é€šè¿‡",
                    "åˆ¤æ–­æ–¹æ³•": method_display,
                    "åŸå› è¯´æ˜": reason,
                    "ç­›é€‰è¯¦æƒ…": detail_text
                }
                filter_details.append(filter_detail)
            
            # æ„å»ºè¾“å‡ºè®°å½•
            output_record = {
                "åºå·": int(resume_number) if str(resume_number).isdigit() else resume_number,
                "å§“å": name,
                "å…³é”®ç”»åƒ": key_profile,
                "åº”è˜å²—ä½": applied_position,
                "AIåˆç­›ç»“æœ": ai_result,
                "æ·˜æ±°åŸå› ": elimination_reason,
                "ç­›é€‰æ¡ä»¶è¯¦æƒ…": filter_details
            }
            
            screening_results.append(output_record)
            logger.info(f"   âœ… æ·»åŠ åˆ°ç»“æœåˆ—è¡¨")
        
        logger.info(f"ğŸ“Š æœ€ç»ˆç­›é€‰ç»“æœæ•°: {len(screening_results)}")
        
        # æŒ‰åºå·æ’åº
        screening_results.sort(key=lambda x: x.get('åºå·', 0) if isinstance(x.get('åºå·'), (int, str)) and str(x.get('åºå·')).isdigit() else 0)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_passed = sum(1 for r in screening_results if r["AIåˆç­›ç»“æœ"] == "æ‹Ÿé€šè¿‡")
        total_count = len(screening_results)
        
        statistics = {
            "total": total_count,
            "passed": total_passed,
            "rejected": total_count - total_passed,
            "elapsed_time": f"{elapsed_time:.2f}ç§’"
        }
        
        print(f"âœ… AI åˆç­›å®Œæˆï¼Œå…±å¤„ç† {total_count} ä»½ç®€å†")
        print(f"   é€šè¿‡: {total_passed} ä»½")
        print(f"   æ·˜æ±°: {total_count - total_passed} ä»½")
        print(f"   è€—æ—¶: {elapsed_time:.2f}ç§’")
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        output_path = os.path.join(os.path.dirname(__file__), "ç®€å†åˆç­›ç»“æœ.json")
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(screening_results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
        # è¿”å›ç»“æœ
        return JSONResponse(content={
            "success": True,
            "message": "ç®€å†åˆç­›å®Œæˆ",
            "data": screening_results,
            "statistics": statistics
        })
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å¤„ç†å¤±è´¥: {str(e)}")
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_dir and os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir)
            except:
                pass


@app.post("/")
async def screen_resumes_root(
    resume_file: UploadFile = File(...),
    position_file: UploadFile = File(...)
):
    """
    æ ¹è·¯å¾„çš„ POST è¯·æ±‚ï¼ˆå…¼å®¹åŸæœ‰æ¥å£ï¼‰
    """
    return await screen_resumes(resume_file, position_file)


if __name__ == "__main__":
    print("=" * 80)
    print("ğŸš€ AIç®€å†åˆç­›ç³»ç»Ÿ - åç«¯æœåŠ¡")
    print("=" * 80)
    print("ğŸ“ æœåŠ¡åœ°å€: http://127.0.0.1:8000")
    print("ğŸ“– API æ–‡æ¡£: http://127.0.0.1:8000/docs")
    print("ğŸ’¡ ä½¿ç”¨çœŸå®çš„ LLM ç­›é€‰å¼•æ“")
    print("=" * 80)
    print()
    
    # å¯åŠ¨æœåŠ¡
    uvicorn.run(
        app,
        host="127.0.0.1",
        port=8000,
        log_level="info"
    )




